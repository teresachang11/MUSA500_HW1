---
title: "MUSA500 - HW1"
author: "Chenxi Zhu, Teresa Chang, and Tiffany Luo "
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 80
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

## 2. Methods

### 2.1 Data Cleaning

### 2.2 Exploratory Data Analysis

### 2.3 Multiple Regression Analysis

### 2.4 Additional Analyses

### 2.5 Software

## 3. Results

```{r load_packages, warning = FALSE, include=FALSE}
options(scipen=10000000)

library(tidyverse)
library(kableExtra)
library(gridExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(scales)
library(stargazer)
library(cowplot)
library(ggpubr)
library(sf)
library(corrr)
library(car)  
library(MASS)
```

### 3.1 Exploratory Results

#### 3.1.1 Summary Statistics

```{r}
data <- read.csv("RegressionData.csv")
```

The summary statistics reveals a diverse and complex socio-economic and housing
landscape. The significant variability in median house values suggests a wide
range of property prices, reflecting diverse regional housing markets and
economic conditions. High standard deviations in the number of households living
in poverty and the percentage of individuals with bachelor's degrees or higher
indicate notable socio-economic disparities across different census block group.

```{r}
MedHouseValue = c('Median House Value', mean(data$MEDHVAL), sd(data$MEDHVAL))
HH_poverty = c('# Households Living in Poverty', mean(data$NBELPOV100), sd(data$NBELPOV100))
bachelor = c('% with Bachelorâ€™s Degrees or Higher', mean(data$PCTBACHMOR), sd(data$PCTBACHMOR))
vacant = c('% of Vacant Houses', mean(data$PCTVACANT), sd(data$PCTVACANT))
SingleHouse = c('% of Single House Units', mean(data$PCTSINGLES), sd(data$PCTSINGLES))

table = as.data.frame(t(data.frame(
              MedHouseValue,
              HH_poverty,
              bachelor,
              vacant,
              SingleHouse))) 

# TODO: rounding the digits
colnames(table) = c("Variable", "Mean", "SD")
table$Mean = as.numeric(table$Mean)
table$SD = as.numeric(table$SD)
table = table %>% mutate(across(where(is.numeric), round, digits=2))

table %>%
  kbl(caption = "Summary Statistics") %>%
  kable_styling() %>%
  kable_classic(html_font = "Cambria", position = "left", full_width = F)

```

#### 3.1.2 Distribution

As observed from the histograms, all variables are not normally distributed but
right skewed. By transforming the variables using `log([VAR])` (or
`log(1+[VAR])` if the variable has any zero values), some distributions of the
transformed variables look normal while some have a large spike at zero. Based
on the comparison, the subsequent analysis and the regression model will use

-   the log-transformed variables `LNMEDHVAL` and `LNNBELPOV100`

-   and the original variables `PCBACHMORE`, `PCTVACANT`, and `PCTSINGLES`.

```{r fig.height = 9, fig.width = 9}
original_vars <- c("MEDHVAL", "PCTBACHMOR", "NBELPOV100", "PCTVACANT", "PCTSINGLES")

for (var in original_vars) {
  log_var_name <- paste0("LN", var)
  data[[log_var_name]] <- ifelse(data[[var]] == 0, log1p(data[[var]]), log(data[[var]]))
}

# Function to plot histogram
plot_histogram <- function(data, var, title) {
  ggplot(data, aes_string(x = var)) + 
    geom_histogram(bins = 25, fill = "skyblue", color = "dark gray") +
    theme_minimal() +
    ggtitle(title) +
    theme(plot.title = element_text(hjust = 0.5))
}

# Plotting histograms
plot_list <- list()
for (var in original_vars) {
  plot_title <- table$Variable[which(original_vars  == var)]
  original_plot <- plot_histogram(data, var, sprintf("Histogram of %s", plot_title))
  log_plot <- plot_histogram(data, paste0("LN", var), sprintf("Histogram of LN %s", plot_title))
  plot_list[[length(plot_list) + 1]] <- original_plot
  plot_list[[length(plot_list) + 1]] <- log_plot
}

# Arrange the plots in a grid
do.call("grid.arrange", c(plot_list, ncol=2))

```

In addition to normality, the other regression assumptions will be examined in a
separate section below (Regression Assumption Checks).

#### 3.1.3 Choropleth Maps

```{r results='hide'}
sfdata <- st_read('RegressionData.shp/RegressionData.shp')
```

```{r}
ggplot(sfdata) +
  geom_sf(aes(fill = LNMEDHVAL), color = NA) +
  scale_fill_viridis_c() +
  theme_minimal() +
  theme(panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(), # Remove background grid
      axis.text = element_blank(), axis.ticks = element_blank(), # Remove axis text and ticks
      axis.title = element_blank()) + # Remove axis titles
  labs(title = "Choropleth Map for Dependent Variable", fill = "LNMEDHVAL")
```

```{r}
vars_to_plot <- c("PCTBACHMOR", "LNNBELPOV", "PCTVACANT", "PCTSINGLES")

# Create a combined plot
plot_list <- list()
for (var in vars_to_plot) {
  p <- ggplot(sfdata) +
    geom_sf(aes(fill = !!sym(var)), color = NA) + # Use 'sym' from rlang to convert string to symbol
    scale_fill_viridis_c(option = "D") +
    theme_void()
  plot_list[[var]] <- p
}

grid.arrange(grobs = plot_list, ncol = 2, top = "Choropleth Maps for Independent Variables")
```

The choropleth maps show varying degrees of similarity and differences. Maps
that are visually similar, such as `PCTBACHMOR` and `LNMEDHVAL`, may indicate a
strong association between higher education levels and property values. In
contrast, dissimilar patterns, like those potentially seen between `LNNBELPOV`
and `LNMEDHVAL`, could suggest an inverse relationship, with higher home values
corresponding to poverty level. The presence of strong visual correlations among
independent variables hints at the possibility of multicollinearity, such as
`PCTBACHMOR` and `LNNBELPOV`. This could complicate the analysis by obscuring
the individual impacts of each predictor. Statistical analysis would be
necessary to confirm these visual assessments.

#### 3.1.4 Correlation Matrix

We can further test multicollinearity with correlation matrix of independent
variables., as shown below. The matrix suggests a weak correlation across
predictors as all correlation coefficients fall within +-0.3. Hence, the matrix
shows that there is no severe multicollinearity, which negates the previous
visual observation from the maps.

```{r, warning=FALSE}
data[c("PCTBACHMOR", "LNNBELPOV100", "PCTVACANT", "PCTSINGLES")] %>% 
  correlate() %>% 
  autoplot() +
  geom_text(aes(label = round(r, digits=2)), size = 3) +
  labs(title = "Correlation Matrix")
```

### 3.2 Regression Results

We regressed the log-transformed median value of housing units `LNMEDHVAL` on
the proportion of residents with at least a bachelor's degree `PCTBACHMOR`, the
log-transformed number of households living in poverty `LNNBELPOV100`, the
proportion of vacant housing units `PCTVACANT`, and the percentage of single
family houses `PCTSINGLES`. The regression output tells us that all independent
variables are statistically significant in explaining the dependent variable
with p\<0.01. The p-value tells us that if there is actually no relationship
between the independent variable and the dependent variable (i.e., if the null
hypothesis that Î²1=0 is actually true), then the probability of getting a
coefficient estimate is less than 0.01. These low p-value indicate that we can
safely reject H0: $Î²_{1}$ = 0 for Ha: $Î²_{1}$ â‰  0, H0: $Î²_{2}$ = 0 for Ha:
$Î²_{2}$ â‰  0, H0: $Î²_{3}$ = 0 for Ha: $Î²_{3}$ â‰  0, and H0: $Î²_{4}$ = 0 for Ha:
$Î²_{4}$ â‰  0, (at most reasonable levels of Î± = P(Type I error)). The percentage
of single family houses and the proportion of residents with at least a
bachelor's degree are positively associated with the dependent variable while
the log-transformed number of households living in poverty and the proportion of
vacant housing units are negatively associated with the dependent variable.

As % with at least a bachelor's degree increases by 1%, the expected change in
median house value is ($ð‘’^{0.021}$ - 1)âˆ— 100% = 2.12%, holding other variables
constant. As % living in poverty increases by 1%, the expected change in median
house value is ($1.01^{-0.078}$ - 1)âˆ— 100% = -0.08%, holding other variables
constant. As % of vacant units increases by 1%, the expected change in median
house value is ($1.01^{-0.019}$ - 1)âˆ— 100% = -0.02%, holding other variables
constant. As % of single housing units increases by 1%, the expected change in
median house value is ($ð‘’^{0.003}$ - 1)âˆ— 100% = 0.30%, holding other variables
constant.

More than two thirds of the variance in the dependent variable is explained by
the model (R2 and Adjusted R2 are 0.662 and 0.661, respectively). The low
p-value associated with the F-ratio shows that we can reject the null hypothesis
that all coefficients in the model are 0.

```{r warning=FALSE}
lm = lm(LNMEDHVAL ~ PCTBACHMOR + LNNBELPOV100 + PCTVACANT + PCTSINGLES, data = data)

stargazer(lm, type = "text", title = "Linear Regression", align = TRUE)
```

Here is the result of error sum of squares for the regression.

```{r}
anova(lm)
```

### 3.3 Regression Assumption Checks

In this section, we will be talking about testing model assumptions: linearity,
residual normality, homoscedasticity, and spatial autocorrelation. Variables
distribution is already discussed in previous section.

#### 3.3.1 Linearity

The scatter plots between the log-transformed median house value and each of the
independent variables exhibit distinct patterns. The plot with the
log-transformed poverty count hints at a negative correlation, where more
poverty may correspond to lower house values. A positive correlation appears
between house value and educational attainment, suggesting that areas with a
higher proportion of residents with at least a bachelor's degree may have higher
property values. Vacancy rates and the proportion of single-family homes do not
show a clear linear trend.

```{r}
data_long <- reshape2::melt(data, id.vars = 'LNMEDHVAL', 
                            measure.vars = c('LNNBELPOV100', 'PCTBACHMOR', 'PCTVACANT', 'PCTSINGLES'))

# Plot using ggplot2 with facet_wrap to create individual plots for each variable
ggplot(data_long, aes(x = value, y = LNMEDHVAL)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~variable, scales = 'free_x') +
  theme_minimal() +
  labs(y = 'Median House Value', x = 'Independent Variable')
```

```{r include=FALSE}
cor(data$LNMEDHVAL, data$LNNBELPOV100, method = c("pearson"), use = "complete.obs")
cor(data$LNMEDHVAL, data$PCTBACHMOR, method = c("pearson"), use = "complete.obs")
cor(data$LNMEDHVAL, data$PCTVACANT, method = c("pearson"), use = "complete.obs")
cor(data$LNMEDHVAL, data$PCTSINGLES, method = c("pearson"), use = "complete.obs")
```

#### 3.3.2 Residual Normality

To test the second assumption, we will plot the distribution of standardized
residuals, which is the raw residual divided by an estimate of the standard
deviation of the residuals. The histogram of standardized residuals looks
normally distributed.

```{r}
data$predvals <- fitted(lm) 
data$resids <- residuals(lm)
data$stdres <- rstandard(lm)

ggplot(data) +
  geom_histogram(aes(x = stdres)) +
  theme_minimal() +
  labs(x = 'Standardized Residuals', y = 'Count')
```

#### 3.3.3 Homoscedasticity

According the the plot of standardized residual by predicted value scatter plot,
the variance of residuals seem different at various predicted value, meaning
heteroscedasticity.

```{r}
ggplot(data, aes(x = predvals, y = stdres)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(y = 'Standardized Residual', x = 'Predicted Value')
```

#### 3.3.4 Spatial autocorrelation

By the choropleth maps we have drawn earlier, block groups that are close
together do have similar values, meaning the observations are not spatially
independent of each other. The choropleth map of the standardized regression
residuals also shows that there are spatial patterns in the standardized
residuals, with areas especially high in standardized residuals, indicating
spatial autocorrelation.

```{r}
sfdata$stdres <- rstandard(lm)
ggplot(sfdata) +
  geom_sf(aes(fill = stdres), color = NA) +
  scale_fill_viridis_c() +
  theme_minimal() +
  theme(panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(), # Remove background grid
      axis.text = element_blank(), axis.ticks = element_blank(), # Remove axis text and ticks
      axis.title = element_blank()) + # Remove axis titles
  labs(title = "Choropleth Map for Standardized Residuals", fill = "stdres")
```

### 3.4 Additional Models

Stepwise regression could automatically select variables for regression model.
Based on the results, all four variables are kept in the final model.

```{r}
step <- stepAIC(lm, direction="both")
step$anova 
```

## 4. Discussion and Limitations
