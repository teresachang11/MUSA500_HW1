---
title: "MUSA500 - HW1"
author: "Chenxi Zhu, Teresa Chang, and Tiffany Luo "
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 80
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

## 2. Methods

### 2.1 Data Cleaning

### 2.2 Exploratory Data Analysis

### 2.3 Multiple Regression Analysis

### 2.4 Additional Analyses

### 2.5 Software

## 3. Results

```{r load_packages, warning = FALSE, include=FALSE}
options(scipen=10000000)

library(tidyverse)
library(kableExtra)
library(gridExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(scales)
library(stargazer)
library(cowplot)
library(ggpubr)
library(sf)
library(corrr)
```

### 3.1 Exploratory Results

#### 3.1.1 Summary Statistics

```{r}
data <- read.csv("RegressionData.csv")
```

The summary statistics reveals a diverse and complex socio-economic and housing
landscape. The significant variability in median house values suggests a wide
range of property prices, reflecting diverse regional housing markets and
economic conditions. High standard deviations in the number of households living
in poverty and the percentage of individuals with bachelor's degrees or higher
indicate notable socio-economic disparities across different census block group.

```{r}
MedHouseValue = c('Median House Value', mean(data$MEDHVAL), sd(data$MEDHVAL))
HH_poverty = c('# Households Living in Poverty', mean(data$NBELPOV100), sd(data$NBELPOV100))
bachelor = c('% with Bachelorâ€™s Degrees or Higher', mean(data$PCTBACHMOR), sd(data$PCTBACHMOR))
vacant = c('% of Vacant Houses', mean(data$PCTVACANT), sd(data$PCTVACANT))
SingleHouse = c('% of Single House Units', mean(data$PCTSINGLES), sd(data$PCTSINGLES))

table = as.data.frame(t(data.frame(
              MedHouseValue,
              HH_poverty,
              bachelor,
              vacant,
              SingleHouse))) 

# TODO: rounding the digits
colnames(table) = c("Variable", "Mean", "SD")
table$Mean = as.numeric(table$Mean)
table$SD = as.numeric(table$SD)
table = table %>% mutate(across(where(is.numeric), round, digits=2))

table %>%
  kbl(caption = "Summary Statistics") %>%
  kable_styling() %>%
  kable_classic(html_font = "Cambria", position = "left", full_width = F)

```

#### 3.1.2 Distribution

As observed from the histograms, all variables are not normally distributed but
right skewed. By transforming the variables using `log([VAR])` (or
`log(1+[VAR])` if the variable has any zero values), some distributions of the
transformed variables look normal while some have a large spike at zero. Based
on the comparison, the subsequent analysis and the regression model will use

-   the log-transformed variables `LNMEDHVAL` and `LNNBELPOV100`

-   and the original variables `PCBACHMORE`, `PCTVACANT`, and `PCTSINGLES`.

```{r fig.height = 9, fig.width = 9}
original_vars <- c("MEDHVAL", "PCTBACHMOR", "NBELPOV100", "PCTVACANT", "PCTSINGLES")

for (var in original_vars) {
  log_var_name <- paste0("LN", var)
  data[[log_var_name]] <- ifelse(data[[var]] == 0, log1p(data[[var]]), log(data[[var]]))
}

# Function to plot histogram
plot_histogram <- function(data, var, title) {
  ggplot(data, aes_string(x = var)) + 
    geom_histogram(bins = 25, fill = "skyblue", color = "dark gray") +
    theme_minimal() +
    ggtitle(title) +
    theme(plot.title = element_text(hjust = 0.5))
}

# Plotting histograms
plot_list <- list()
for (var in original_vars) {
  plot_title <- table$Variable[which(original_vars  == var)]
  original_plot <- plot_histogram(data, var, sprintf("Histogram of %s", plot_title))
  log_plot <- plot_histogram(data, paste0("LN", var), sprintf("Histogram of LN %s", plot_title))
  plot_list[[length(plot_list) + 1]] <- original_plot
  plot_list[[length(plot_list) + 1]] <- log_plot
}

# Arrange the plots in a grid
do.call("grid.arrange", c(plot_list, ncol=2))

```

In addition to normality, the other regression assumptions will be examined in a
separate section below (Regression Assumption Checks).

#### 3.1.3 Choropleth Maps

```{r results='hide'}
sfdata <- st_read('RegressionData.shp/RegressionData.shp')
```

```{r}
ggplot(sfdata) +
  geom_sf(aes(fill = LNMEDHVAL), color = NA) +
  scale_fill_viridis_c() +
  theme_minimal() +
  theme(panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(), # Remove background grid
      axis.text = element_blank(), axis.ticks = element_blank(), # Remove axis text and ticks
      axis.title = element_blank()) + # Remove axis titles
  labs(title = "Choropleth Map for Dependent Variable", fill = "LNMEDHVAL")
```

```{r}
vars_to_plot <- c("PCTBACHMOR", "LNNBELPOV", "PCTVACANT", "PCTSINGLES")

# Create a combined plot
plot_list <- list()
for (var in vars_to_plot) {
  p <- ggplot(sfdata) +
    geom_sf(aes(fill = !!sym(var)), color = NA) + # Use 'sym' from rlang to convert string to symbol
    scale_fill_viridis_c(option = "D") +
    theme_void()
  plot_list[[var]] <- p
}

grid.arrange(grobs = plot_list, ncol = 2, top = "Choropleth Maps for Independent Variables")
```

The choropleth maps show varying degrees of similarity and differences. Maps
that are visually similar, such as `PCTBACHMOR` and `LNMEDHVAL`, may indicate a
strong association between higher education levels and property values. In
contrast, dissimilar patterns, like those potentially seen between `LNNBELPOV`
and `LNMEDHVAL`, could suggest an inverse relationship, with higher home values
corresponding to poverty level. The presence of strong visual correlations among
independent variables hints at the possibility of multicollinearity, such as
`PCTBACHMOR` and `LNNBELPOV`. This could complicate the analysis by obscuring
the individual impacts of each predictor. Statistical analysis would be
necessary to confirm these visual assessments.

#### 3.1.4 Correlation Matrix

We can further test multicollinearity with correlation matrix of independent
variables., as shown below. The matrix suggests a weak correlation across
predictors as all correlation coefficients fall within +-0.3. Hence, the matrix
shows that there is no severe multicollinearity, which negates the previous
visual observation from the maps.

```{r}
data[c("PCTBACHMOR", "LNNBELPOV100", "PCTVACANT", "PCTSINGLES")] %>% 
  correlate() %>% 
  autoplot() +
  geom_text(aes(label = round(r, digits=2)), size = 3) +
  labs(title = "Correlation Matrix")
```

### 3.2 Regression Results

i.  Present the regression output from R. Be sure that your output presents the
    parameter estimates (and associated standard errors, t-statistics and
    p-values), as well as the R2, the adjusted R2, and the relevant F-ratio and
    associated p-value.

ii. Referencing the regression output in (i) above, interpret the results as in
    the example included above this report outline.

NOTE: YOUR DEPENDENT VARIABLE (AND SOME PREDICTORS) WOULD BE LOG-TRANSFORMED,
UNLIKE IN THE EXAMPLE HERE. LOOK AT THE SLIDES FOR EXAMPLES OF INTERPRETING
REGRESSION OUTPUT WITH LOG-TRANSFORMED VARIABLES.

### 3.3 Regression Assumption Checks

In this section, we will be talking about testing model assumptions: . Variables
distribution is already discussed in previous section.

The scatter plots between the log-transformed median house value and each of the
independent variables exhibit distinct patterns. The plot with the
log-transformed poverty count hints at a negative correlation, where more
poverty may correspond to lower house values. A positive correlation appears
between house value and educational attainment, suggesting that areas with a
higher proportion of residents with at least a bachelor\'s degree may have
higher property values. Vacancy rates and the proportion of single-family homes
do not show a clear linear trend.

```{r}
data_long <- reshape2::melt(data, id.vars = 'LNMEDHVAL', 
                            measure.vars = c('LNNBELPOV100', 'PCTBACHMOR', 'PCTVACANT', 'PCTSINGLES'))

# Plot using ggplot2 with facet_wrap to create individual plots for each variable
ggplot(data_long, aes(x = value, y = LNMEDHVAL)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~variable, scales = 'free_x') +
  theme_minimal() +
  labs(y = 'Median House Value', x = 'Independent Variable')
```

```{r}
cor(data$LNMEDHVAL, data$LNNBELPOV100, method = c("pearson"), use = "complete.obs")
cor(data$LNMEDHVAL, data$PCTBACHMOR, method = c("pearson"), use = "complete.obs")
cor(data$LNMEDHVAL, data$PCTVACANT, method = c("pearson"), use = "complete.obs")
cor(data$LNMEDHVAL, data$PCTSINGLES, method = c("pearson"), use = "complete.obs")
```

i.  Present the histogram of the standardized residuals. State whether the
    residuals look normal.

ii. Present the 'Standardized Residual by Predicted Value' scatter plot. What
    conclusions can you draw from that? Does there seem to be
    heteroscedasticity? Do there seem to be outliers? Anything else? Discuss.

<!-- -->

1.  Mention what standardized residuals are.

<!-- -->

v.  Referencing the maps of the dependent variable and the predictors that you
    presented earlier, state whether there seems to be spatial autocorrelation
    in your variables. That is, does it seem that the observations (i.e., block
    groups) are independent of each other? Briefly discuss.

<!-- -->

vi. Now, present the choropleth map of the standardized regression residuals. Do
    there seem to be any noticeable spatial patterns in them? That is, do they
    seem to be spatially autocorrelated?

<!-- -->

1.  You will examine the spatial autocorrelation of the variables and residuals
    and run spatial regressions in the next assignment.

    ```{r}

    A <- ggscatter(data, x = "LNMEDHVAL", y = "LNNBELPOV100", 
              add = "reg.line", conf.int = TRUE, 
              cor.coef = TRUE, cor.method = "pearson",
              xlab = "LNMEDHVAL", ylab = "LNNBELPOV100")

    B <- ggscatter(data, x = "LNMEDHVAL", y = "PCTBACHMOR", 
              add = "reg.line", conf.int = TRUE, 
              cor.coef = TRUE, cor.method = "pearson",
              xlab = "LNMEDHVAL", ylab = "PCTBACHMOR")


    C <- ggscatter(data, x = "LNMEDHVAL", y = "PCTVACANT", 
              add = "reg.line", conf.int = TRUE, 
              cor.coef = TRUE, cor.method = "pearson",
              xlab = "LNMEDHVAL", ylab = "PCTVACANT")

    D <- ggscatter(data, x = "LNMEDHVAL", y = "PCTSINGLES", 
              add = "reg.line", conf.int = TRUE, 
              cor.coef = TRUE, cor.method = "pearson",
              xlab = "LNMEDHVAL", ylab = "PCTSINGLES")

    ggarrange(A, B, C, D + rremove("x.text"),  heights = c(10, 10),
              labels = c("A", "B", "C", "D"),
              ncol = 2, nrow = 2)
    ```

### 3.4 Additional Models

i.  Present the results of the stepwise regression and state whether all 4
    predictors in the original model are kept in the final model.

ii. Present the cross-validation results -- that is, compare the RMSE of the
    original model that includes all 4 predictors with the RMSE of the model
    that only includes PCTVACANT and MEDHHINC as predictors.

## 4. Discussion and Limitations
